---
title: "Session 2.2"
subtitle: "Saving and analysing data"
format: 
   revealjs:
      incremental: true
      theme: solarized
editor: "visual"
jupyter: wsl_prec
bibliography: references.bib
csl: apa.csl
---

# Welcome back!!{.smaller}



 - Welcome back!! 
 - In the last few sessions we've been getting you up to speed with the *basics* of python and `pandas`
 - We've covered a lot of ground, but we've also been trying to keep it simple.
    - Data types like:
        - `int`, `float`, `str`, `bool`
        - `list`, `tuple`, `dict`
        - `pathlib.Path`, `pandas.DataFrame`
    - functions, methods, and attributes
    - `for` loops

 
# `Pandas recap` {.smaller}

 - We've also been introducing you to the `pandas` module
 - We've shown you how to create `DataFrames` from scratch
 - How to `read` in data from `.csv` and `.xlsx` files
   - `pd.read_csv()`, `pd.read_excel()`
 - We've shown you how to `clean` your data
    - `df.dropna()`, `df.replace()`
 - We've shown you how to `examine` your data
    - `df.head()`, `df.tail()`, `df[column].value_counts()`, `df.columns`
 - We've shown you how to `slice` your data
    - `df.iloc[]`, `df.loc[]`, `df[]`
    - `df[df['column'] == 'value']`

# `Pandas recap` {.smaller}

 - The next thing for you to do is practice 'recalling' this stuff so...

. . .

**It's time for a quiz!**

 - You know where to go!
 - You know they're not graded




# Set up for the session {.smaller}

 - This session we're going to 'finish' up the introductory python part of these workshops by generating some descriptive statistics, simple plots, and saving output.
 -  But first things first - we need to import the modules we'll need for this session

. . .

```{python}
#| echo: true
#| eval: true
# import the needed modules in this cell
import pandas as pd # for working with dataframes
import pathlib as pl # for working with file paths
import numpy as np # to let me use the np.nan value in the next cell. 
```

# Set up for the session {.smaller}

 - Excellent! Modules imported and now we need some data.
 - Let's go through the cell below to create the `movies_df` so that we have some data to work with. 

# Set up for the session {.smaller}


```{python}
#| echo: true
#| eval: true
# initialise some list objects that contains our data, this could also be a list of lists, or a dict of lists for example
director = ['John Carpenter', '', 'Nicolas Winding Refn', 'Matthijs van Heijningen', 'Damien Chazelle', 'Dennis Villanueve', 'Coen Brothers', 'Kelly Asbury', 'Edgar Wright', 'Coen Brothers']
names = ['The Thing', 'Blade Runner 2049', 'Drive',  'The Thing', 'Whiplash', 'Arrival', 'No Country for Old Men', 'Shrek 2', 'Hot Fuzz', 'Fargo']
genre = ['Horror', 'Sci-Fi', 'Action', 'Horror', 'Drama', 'Sci-Fi', 'Drama', 'Comedy', 'Comedy', 'Dark Comedy']
year = ['1982', '2017', '2011', '2011', '2014', '2016', '2007', '2004', '2007', '1996']
imdb_score = [82, 80, 78, 62, np.nan, 79, 82, 73, 78, 81]
rt_critics = [82, 88, 93, 34, np.nan, 94, 93, 89, 91, 94]
rt_fans = [92.0, 79.0, 42.0, 82.0, 86.0, 69.0, 89.0, 93.0, 94.0, 79.0] 
lead = ['male', 'Male', 'm', 'Female', 'm', 'Male', 'fem', 'Orgre', 'Male', 'Male']



#turning those lists into a dataframe
movies_df = pd.DataFrame(# opening brackets but moving to new line for readability, note the uppercase D and F in the call
    list(zip(director, names, genre, year, imdb_score, rt_critics, rt_fans, lead)), #first argument note the comma at the end of it, this is a couple of nested functions
    columns = ['Director', 'Movie Title', 'Genre', 'Year of Release', 'ImdB Score', 'Rotten Tomatoes Score','Rotten Tomatoes Fan Score', 'Gender of Lead']# second argument , passing a list to the columns arguments
    )# closing the first pair of brackets to complete the function call
movies_df.to_csv('movies_df_2_2.csv', index=False)#saving the dataframe to a csv file
movies_df.columns = [i.lower().replace(' ', '_') for i in movies_df.columns] #capitalising the column names
# cleaning the data a little. 
movies_df = movies_df.replace(r'^\s*$', np.nan, regex=True).dropna().reset_index(drop=True) #
#notice how we've 'chained' a bunch of methods together to make all empty cells appear as 'np.nan', then dropping all 'nan' cells then resetting the index
#that one line of code! Imagine if it was a huge data set

movies_df.iloc[:, -1:] = movies_df.iloc[:, -1:].replace(to_replace = ["m"], value = "Male") #Fixing the male values
movies_df.iloc[:, -1:] = movies_df.iloc[:, -1:].replace(to_replace = ["fem"], value = "Female") # fixing the female values
movies_df['gender_of_lead'] = movies_df['gender_of_lead'].str.title()
```


# ph1 {.smaller}

```{python}
#| echo: false
#| eval: true
movies_df.columns
```


# Set up for the session {.smaller}

 - You can download the data (movies_df_2_2.csv) from Brightspace
 - Use the `pd.read_csv()` method to import the data into a new `DataFrame` called `movies_df`
 - Take your time and call me if you get stuck. 
 - Once you have the data imported, take a look at the `head` of the data to make sure it's all there.
 - Check the `df.shape attribute` of the data to see how many rows and columns you have.
 - Use a for loop to print out the `columns` of the data.
 - From your previous notebook you should have some examples of how to clean the data
 - `replace` any missing values with `np.nan` and then `drop` any rows that contain `np.nan` values.
 - fix and inconsistencies in the data entries with `value_counts()` and `replace()`
 - Finally, `reset` the index of the dataframe so that it starts at 0.


# Saving stuff {.smaller}

 - One of the key things we might want to do is **save**  things. 
 - You might want to save clean data once you've made it.
    - In this case I've made the dataset somewhat from scratch and maybe I want to be able to save it so that we can send it onto other researchers,
    - Or maybe you have done lots of work cleaning a data set and you want to save it so that you can analyse it later. 
 - You might have made a table, or a chart, or a plot that you want to save so that you can use it in a report or a presentation.

# Saving data {.smaller}

 - Saving your data is a good idea 
 - Fortunately the syntax for saving a dataframe is, at the heart of it, really easy. 

. . .

```{{python}}
#saving a dataframe to a csv file
name_of_dataframe.to_csv('path\to\where\you\want\to\save\filename.csv', index=False)

#saving a dataframe to an excel file
name_of_dataframe.to_excel('path\to\where\you\want\to\save\filename.xlsx', index=False)
``` 


# Saving data {.smaller}

 - So above, we have two examples of saving a `pandas DataFrame`, one to a `.csv` file and one to a `.xlsx` file. Let's just take a second and walk through the actual syntax we used above. 
    1. The first thing we do is call the `variable` we want to work on, in this case using the name of our dataframe
    2. We follow this with a fullstop `.` because saving a file is `method `
    3. This is followed by `to_` and then the type of file we're exporting to, so `to_csv` for csvs or `to_excel` 
    4. Then we open brackets `()` and we pass the `path` to where we want the file to live 
        A. This can be an `r-string` 
        B. Or it can be a `pl.Path()` object
 - But it has to end in `\filename.filetype` (the filetype is the `.csv` or `.xlsx`, also called the `suffix` of the file)

. . .

Using an `r-string` or a `Path` is often a matter of personal preference, but we would encourage you to work with `Path` objects more often because they can be a lot more flexible. Let's take an aside for a few minutes and look at what we can do with `Paths` to make our lives easier. 

# Path components {.smaller} 

 - Just like a `DataFrame` has `attributes` like `.columns` and `.shape`
 - A `Path` object also has attributes that can be useful, and these attributes are basically just the components of a file path.
 - These `attributes` allow us to pick apart a `path` so that we can use the bits of it we need.
 - To get a sense of this, in the cell below we'll create a `Path` to the `csv`  

. . .

```{python}
#| echo: true
#| eval: true
#make your path object on the next line
csv_file = pl.Path(r'../../data/movies_df_2_2.csv')#using the ../../ to move up two directories to the data folder
```

Now that we have an example path, we can can look at some of the attributes.

# `.name` {.smaller}

 - The first attribute we're going to look at is the `name` attribute of a `Path` object. 
 - This is the name of the file or folder that the `path` points to including the file `suffix`. 
 - This is useful because it allows us to get the name of the file or folder without having to parse the `path` string. 


```{python}
#| echo: true
#| eval: true
# printing the file name
print(csv_file.name)# note that it is not followed by `()` because it is an attribute not a method
```


# `stem` and `suffix` {.smaller}

 - The `name` attribute is useful, but sometimes we want to get the `stem` of the file (the name without the `suffix`) or the `suffix` of the file (the `.csv` or `.xlsx` at the end of the name) 
 - Like if we specficially want to find files with the same `stem` but different `suffixes` or if we want to save a new file with the same `stem` but a different `suffix`.

```{python}
#| echo: true
#| eval: true
# printing the stem of the file
print(csv_file.stem)
# printing the suffix of the file
print(csv_file.suffix)
```


# `stem` and `suffix` {.smaller}
 
 - Boom. 
 - You'll notice that the filename also has the `.csv` `suffix`.
 -  Obviously if it was an excel workbook the extension would be `.xlsx` and if it was a jupyter notebook it would be `.ipynb`. 
 - All of these `attributes` return `strings` that you can perform all the usual `string operations` on, and we know how much you love those (honestly, it's endearing).
 - So you can call `csv_file.stem.upper()` and it will return the `stem` of the file in uppercase.
 - Or you can call `csv_file.suffix.replace('.', '')` and it will return the `suffix` of the file without the `.` at the start.


# parent {.smaller}

 - The `parent` attribute of a `Path` is the `folder` one level up from the file or folder that the `path` points to.
 - So if the full `path` is 
      - `C:\Users\username\Documents\programming_club\data\movies_df_2_2.csv`
 - Then the `parent` of the `path` is
      - `C:\Users\username\Documents\programming_club\data`

```{python}
#| echo: true
#| eval: true
# printing the parent of the file
print(csv_file.parent)
```

# `paths` and `saving` {.smaller}

- Now that we know about some of these `attributes` we can use them to make our lives a little easier when we're saving files.
- For example, we can use the `path` we saved to the `csv` file to save a new file in the same folder as the `csv` file without overwriting our old file.
- We just need to use the parent of the `path` and add a new `.name` (which includes with `suffix`).
- `Pathlib` is really good at this because it allows us to use `/` (forwardslash) to join a `string` onto the end of a `Path` object.

. . .

```{{python}}
# new file path
new_csv_file = csv_file.parent / 'new_filename.csv'
```

# `paths` and `saving` {.smaller}

 - Or what if you wanted to save it into a another folder in the same project directory?
 - You could use the `parent` of the `parent`!!

. . .

```{{python}}
# new file path
new_csv_file = csv_file.parent.parent / 'processed_data/new_filename.csv'
```

# `paths` and `saving` {.smaller}

 - There's lots you can do with `pathlib` and we've only just scratched the surface.
 - My favourite is to use the `pathlib` `.iterdir()` method to `loop` through all the files in a folder and do something with them.
 - `[i for i in csv_file.parent.iterdir()]` will return a list of all the files in the folder that the `csv_file` is in.
 - But thats a story for another day.

# Saving data {.smaller}

 - Your next task is to save the 'cleaned' `movies_df` to a new `csv` file so that you don't lose all the hard work you've done cleaning it up.
 - I suggest you save it to a csv with the `df.to_csv()` method. 
 - Pass the `path` between the brackets and make sure you set `index = False` so that the `index` of the `df` doesn't show up as a column in the exported `csv` file.
 - Be really careful with the `path` you pass to the `to_csv()` method, you don't want to overwrite your original data (this is where the `pathlib` `attributes` can be really useful).
 - But if you do overwrite your original data, don't worry, you can always download the file again, but that not always be true of the data you're working with.

# Descriptive statistics {.smaller}

 - Now that we've saved our data, we can start to look at some of the `descriptive statistics` of the data.
 - You all know well what descriptive stats are, you've made lots of tables in your time, but we're going to look at how to do this in `pandas`.
 - We can look at things like the `mean`, `median`, `mode`, `standard deviation`, `variance`, `range`, `quartiles`, and `percentiles` of the data.
 - We can use the `df.describe()` method to get a summary of the data in the `DataFrame` (and with quarto we can render them in apa, but thats for later)

# Descriptive statistics {.smaller}

 - The `df.describe()` method is a really useful method for getting a summary of the data in a `DataFrame`.
 - It can be called on a whole `DataFrame` or on a single `column` of a `DataFrame`.
 - It returns a `DataFrame` with the `mean`, `standard deviation`, `min`, `max`, `quartiles`, and `count` of the data in the `DataFrame`.
 - Think about how useful that is for a second.

# `.describe()` {.smaller}

 - Let's take a look at the `describe()` method in action.

. . .

```{python}
#| echo: true
#| eval: true
desc = movies_df.describe()# describe the whole dataframe
desc
```

# `.describe()` {.smaller}

 - So you can see that the `describe()` method returns a `DataFrame` with the major `descriptive statistics` for the `numberical` columns in the `DataFrame`.
 - It's really easy to clean this up and make it look nice.


. . .

```{python}
#| echo: true
#| eval: true
desc.columns = [i.replace('_', ' ').title() for i in desc.columns]#cleaning up the column names
desc.index = [i.title() for i in desc.index]#cleaning up the index
desc.round(2)#rounding the numbers to 2 decimal places
```


# `.describe()` {.smaller}

 - We can also just slice the `DataFrame` returned by the `describe()` method to get specific stats

. . .

```{python}
#| echo: true
#| eval: true
desc.loc[['Mean', 'Std', 'Min', 'Max']]
```


# `.describe()` {.smaller}

 - We can also call the `describe()` method on a single `column` of a `DataFrame` to get the `descriptive statistics` for that `column`.

. . .

```{python}
#| echo: true
#| eval: true

movies_df['director'].describe()
```

. . . 

```{python}
#| echo: true
#| eval: true

movies_df['imdb_score'].describe()
```

# `.describe()` {.smaller}

   - The `describe()` method is really useful for getting a quick summary of the data in a `DataFrame`.
   - But what if we want to get the `mode` of the data?
   - Or the `quartiles` of the data?
   - Or the `percentiles` of the data?
   - We can use the `df.mode()`, `df.min()`, `df.max()`, `df.quantile()`, and `df.percentile()` methods to get these stats.
   - Let's take a look at these in action.

# other stats {.smaller}
 
  - Just like `.describe()` we can call these methods on a whole `DataFrame` or on a single `column` of a `DataFrame`.
  - But we need to specify only numberical columns when we call these methods on a whole `DataFrame`.

. . .

```{python}
#| echo: true
#| eval: true

movies_df[['imdb_score', 'rotten_tomatoes_score', 'rotten_tomatoes_fan_score']].mode()#mode of the imdb_score column
```

. . .

```{python}
#| echo: true
#| eval: true

movies_df['imdb_score'].mode()#mode of the imdb_score column
```


# other stats {.smaller}

 - We can use that `syntax` for any individual descriptive stat we might want
 - so  `.quantile()`, `.percentile()`, `.std()`, `.var()`, `.mean()`, `.median()`, `.mode()`, `.min()`, `.max()`

. . .

```{python}
#| echo: true
#| eval: true

print(movies_df['imdb_score'].quantile(0.25))#first quartile of the imdb_score column
print(movies_df['imdb_score'].quantile(0.75))#third quartile of the imdb_score column
print(movies_df['imdb_score'].mean())#mean of the imdb_score column
```


# other stats {.smaller}

 - We can use that to add to our `desc` dataframe to get a more complete picture of the data
 - We can, for example, add the `mode` of the data to the `desc` dataframe 

. . .

```{python}
#| echo: true
#| eval: true
# adding the mode of the data to the desc dataframe
desc.loc['Mode'] = movies_df.mode().iloc[0]
desc.round(2)
``` 


# other stats {.smaller}

 - So you can see that we can get a lot of `descriptive statistics` from a `DataFrame` really easily.
 - As an academic writer you can then use these in lots of ways. 
 - You can not only make tables of these stats, but you can also use them in your writing to describe the data you're working with.

