{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 - Lets get down to business!\n",
    "\n",
    "Hello and welcome back to week 5 of our python for SPSS users workshops. \n",
    "\n",
    "This is the fist session where you will actually start to work with data in python, but before we start with that we just want to remind you that, even though there will be nuances to the `syntax` we use when when working with data, we have tried to introduce you to the fundamentals of each step. We'll do our best to point you to the previous resources or other online resources that you can use as you go. \n",
    "\n",
    "So, rather than recaping anything this week, we're going to jump into it, but the earlier workbooks and word documents are always there for you to go back to.\n",
    "\n",
    "With that in mind... lets do this.\n",
    "\n",
    "## Part 1 - set up and work flow. \n",
    "\n",
    "OK, the first part of any project is the set up. We can't stress enough how important it is to have a consistent workflow when working on a project, as anyone who has ever saved an assignment and then forgotten where they saved it will tell you. What we're going to quickly go through here is **an** example of how to do this, you might find other ways that suits you better, making small changes or laying things out differently, but these steps are the bare minimum, and while you can (and should) add things if they seem useful, there would need to be a very good reason to skip any of them.  \n",
    "\n",
    "### Create your directory\n",
    "A directory is another name for a 'folder' on your computer and every project you work on should have it's own directory where everything connected to that project is stored. We covered this in week one when we asked you to create a directory called something like 'Programming club'. This really should be the first step in any project, even if you're just playing around with some code. \n",
    "\n",
    "#### Create your subdirectories\n",
    "A sub-directory is just a folder that exists within another folder, sometimes you'll see them called sub-folders, and we use them to help us keep track of a project, and to make sure that there is some reasonable order to the files that are required. In general it is good practice to have:\n",
    "\n",
    " 1. A folder that contains all of your code - this is generally called 'src'\n",
    " 2. A folder that contains all of your data - this is called (in a surprising twist) 'data'\n",
    " 3. A folder that contains any output from your work, like text files, or graphs/figures - this is called 'output'\n",
    "\n",
    "Can you add other folders? Of course. Can you put folders within folders (to seperate old files from new files for example) again, please do! These directories are there to help you, so set them up as you will, [this paper](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510) is a really good place to look for guidance on how to organise your project. We suggest you give it a read whenever, but honestly, untill you've got a couple of small projects under your belt, a lot of it won't really make sense to you. \n",
    "\n",
    "In week 1 of these workshops we got you to set up a directory and subdirectories for these workshops, we have been encouraging you to save all the note books for each week in the 'src' folder and any of the preparatory word docs in a 'preparation' folder, so you can see that we added to the three basic sub-folders already with the 'preparation' sub-folder, so again, make it work for you. You can always add folders later in a project if they're needed, or you can move things into other sub-directories if you need to, but starting out with a structure in place is so valuable (trust us).\n",
    "\n",
    "You don't need to do this again for these workshops, we already had you do this in week 1, but we wanted to make it explicite. Its an important first step. \n",
    "\n",
    "*In the future you will come across something called 'Git' or 'version control' and we encourage you to learn about it and something called 'github.com', it's really great, but we didn't want to overburden you with new stuff to early. If you're interested in it we can try to run a session on it, or you can check out the [git for poets](https://www.youtube.com/watch?v=BCQHnlnPusY&list=PLozRqGzj97d02YjR5JVqDwN2K0cAiT7VK) youtube tutorial (it's areally good start)*\n",
    "\n",
    "\n",
    "### Create your virtual environment\n",
    "\n",
    "**We. Can't. Stress. Enough.** How important it is to any project in python, data projects or otherwise, to use `virtual environments` also called `venvs`. We covered this in the sessions in week 4 but just to reiterate the point here. Python and the modules that we use in our projects are always growing and changing, new functionality is always being added and existing functionality is always being improved. This means that over time, code that you have written might stop working. This doesn't happen often, and it never happens out-of-the-blue, but it does happen. Imagine going back to a project after the summer holidays, for example, or switching over to a new device after there has been a significant update to python, and needing to go back through all your code to find `depreciated` (outdated) `code` that no longer works and rewtire all of it to get your results again. Virtual environments help to avoid this. \n",
    "\n",
    "If you haven't set up a virtual environment yet, we sent out a document called 'Setting up a Virtual Environment with Anaconda.docx' that you should work through now, so that you have one for these workshops, but if you set one up last week, you can just continue to use that one. Don't be afraid to ask questions in the lab sessions (or drop us an email) if you need more help with it. \n",
    "\n",
    "#### Installing modules (also called libraries or packages)\n",
    "Generally, when you are working on a project there will be `modules` that you know you'll need before you start and you want to make sure that those modules are installed when you create the `virtual environment`. For example, when working on an SPSS-like data project you'll need `pandas`, `matplotlib` and `scipy.stats` (theres others but these are the ones we reach for most often), and, as we outlined in the'Setting up a Virtual Environment with Anaconda.docx' guide, we would just install them with pip:\n",
    "\n",
    "```\n",
    "> pip install pandas \n",
    "\n",
    "```\n",
    "\n",
    "You can always go back and install more later by reactivating your `venv` and just running another `pip` call, and this will happen fairly often when you start out, but it's a good idea to just install the ones you know you'll need at the outset. \n",
    "\n",
    "### Put the files you need where you need them. \n",
    "So now that you have your directory set up and you've made your `venv` you just need to bring any files that you know you'll need together to be ready to start writing code. So for example, we emailed you a some datafiles called `raw_data_spss.sav` and `raw_data_csv.csv`, so you should put those files in the 'data' sub-directory, if you had other files that needed to be there to start the project, like maybe a codebook file, or an outline text document, you might put them in an appropriate sub-directory too. \n",
    "\n",
    "\n",
    "\n",
    "And with that you're basically ready to make your first python file. In this case you'll be working in this notebook, but in future you will open VScode (or another IDE if you find one you like) and get to work. \n",
    "\n",
    "\n",
    "## Part 2 - get on with it lads!\n",
    "\n",
    "Ok ok. You're clearly ready to start working, so lets get to it. \n",
    "\n",
    "### Importing modules\n",
    "\n",
    "Just like setting up your folder structure and `venv` is the start of any project, the start of any python file (whether it's a jupyter notebook or just a normal python file), is to `import` the modules you'll be using. We do this in the first cell of our notebook for a few reasons. \n",
    "\n",
    " 1. It helps others get a sense of the what the file is for, kind of like an abstract\n",
    " 2. It condenses all of the `import` statments into one area so they're easy to find it there's a problem (you'd be amazed how much of coding is doing things 'in case')\n",
    " 3. It is a convention. Other pythonistas do it that way and there isn't a good enough reason to change it\n",
    "\n",
    "You could absolutly just import the modules when you need them, but that would make your code confusing for others and harder for you to debug, so... don't be *that guy*. \n",
    "\n",
    "For today we'll be importing, inspecting, and doing a little data cleaning so for today all we're going to `import` is `pandas`, `pathlib` and `datetime`. `Pandas` is the only 3rd party module, the other two are part of the [python standard library](https://docs.python.org/3/library/index.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib as pl# this module lets us work with directory paths\n",
    "import datetime as dt# this helps us to pars dates and times\n",
    "import pandas as pd# this is what lets us make, import and work with tabular data\n",
    "\n",
    "#don't forget to run this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're off... we have just imported the modules we'll need for the project, which means we now have all the `functions` and `classes` (we'll explain this in a minute) at our disposal to use as we need. Now we *could* just have written\n",
    "\n",
    "```\n",
    "import pathlib\n",
    "import datetime\n",
    "import pandas\n",
    "\n",
    "```\n",
    "\n",
    "and it would have done the samething, but using `as` and then providing a shorter tag like `pl` or `pd` means that we don't have to type the full name of the `module` everytime we want to use some of it's functionality. This will make more sense as we go along so... let's.. go along...\n",
    "\n",
    "\n",
    "## telling python where things are on our computer (working with `paths`)\n",
    "\n",
    "Much like when working in SPSS, we have to tell python which file we actually want to work with. In SPSS you often do this by clicking 'file' then clicking 'open', then 'data' and then a filexplorer window opens and you hunt for the file you want, then double click it, and then wait for SPSS to load in the `.sav` file (probably cooking a 3 course meal in the meantime). In contrast, all we need to do in python is enter the `path` to our file, and then we can just get python to work with that file. \n",
    "\n",
    "### ok but what is a `path`?\n",
    "\n",
    "You probably know (but it's ok if you don't) that every file on your computer has an address, or a location where it is 'stored' on your computers harddrive, files are stored in directories which are (often) in other directories, which are located on your drive (unless you have multiple hardrives or are using an external hard drive/usb stick). For example, you might have a song on your computer which lives in your music folder, which is in your Documents folder, which is in your C: drive. Or you might have a Word doc that you're working on for one of your classes, which is on your Desktop, which is really just a directory (folder) on your harddrive. \n",
    "\n",
    "The `path` is just the directions that the computer needs to follow - listing each directory along the way - to get to your file. So in the song example above, on a Windows computer the `path` to our song (the song's address) would be something like \n",
    "\n",
    "```\n",
    "C:\\\\users\\user.name\\Documents\\Music\\song.mp3\n",
    "```\n",
    "\n",
    "Or for the Word doc example, if you were using a Mac the `path` might be\n",
    "\n",
    "```\n",
    "/Users/username/Desktop/assignment.docx\n",
    "```\n",
    "\n",
    "So simply put the `path` just lists each directory we need to go through to get to a file, with each directory seperated by a slash. On Windows systems it's a backslach (`\\`) and on MacOS it's a forwardslash (`/`). Although paths might seem complicated, they are basically just a special type of `string` and thanks to `pathlib` we can do lots of cool things with them, as well as the `string operations` that we've covered earlier.\n",
    "\n",
    "#### where to get the `path` from\n",
    "You don't *need* to just remember the full `path` for a file or folder, you can always just go to the file on your computer (using file explorer on windows or finder on MacOS) and copy the `path`, but, if you have followed the setup steps we suggested up above you can find your file in the 'Explorer' pane in VScode, right click on your file and select '`copy path`', once you've done this you can just paste your `path` in as a `string` (so make sure you add the quotation marks) and then we can tell python that this is a `path` by using the `constructor` (don't worry we'll explain this) like so:\n",
    "\n",
    "```\n",
    "path_to_my_file = pl.Path('C:\\Users\\your.username\\OneDrive - University of Limerick\\Documents\\GitHub\\ULpsych_programing_club\\data\\raw_data_spss.sav') # note the upper-case 'P' at the start of Path()\n",
    "\n",
    "```\n",
    "\n",
    "If you look at the line of code above, all we did was create a `Path` object and passed it to a `variable` called `path_to_my_file`. \n",
    "\n",
    "\n",
    "The `pl.Path()` bit means that we are using the `Path()` `constructor` (which is just a kind of `function`, again we'll explain them later) from the `Pathlib` module. Because we `imported Pathlib` as `pl` we don't need to type `pathlib.Path()`. \n",
    "\n",
    "In the cell below create a `Path` object for the .csv version of the data\n",
    "\n",
    "##### *note about taking in files from windows computers*\n",
    "\n",
    "*because windows computers use '\\\\' we need to put an r immediately before the string to make python interpret the \\ properly. This is called an `rstring` meaning 'raw string' just like `f-string` stands for 'formatted string'. If you're on a mac you don't need to worry about this.*\n",
    "\n",
    "*so on a windows computer it would look like*\n",
    "```\n",
    "my_path = pl.Path(r'path\\to\\my\\file.doc')# note the 'r' before the quotation marks\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create you Path objects here\n",
    "\n",
    "csvfile = pl.Path()#copy the path for the spss file in here\n",
    "\n",
    "#Don't forget to run this cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have you have the `Path` objects created there's loads you can do with them. [This tutorial](https://realpython.com/python-pathlib/#picking-out-components-of-a-path) is a really good introduction to working with `pathlib` but for now we just need to the `paths` to allow us to import the data into python. \n",
    "\n",
    "## The pandas `DataFrame`\n",
    "\n",
    "Pandas is the main program used for handling SPSS like data, it's really powerful and it has a lot of built-in functionality that allows us to import, clean and process data, to run simple analysis, and to produce graphs and charts. It can also be extended with other modules to make working in python even more powerful (and fun) but right now we're going to focus on the `DataFrame` because this is the object that will actually contain our data. \n",
    "\n",
    "In essence a dataframe is just like the 'Data view' in SPSS or an excel spreadsheet, it's made up of columns and rows, where each columns represents  one of our measurement variables and each row represents one of our observations (or participants in most psychology data). This is called `tabular data` because it's basically just a big table.  \n",
    "\n",
    "\n",
    "| | participant name | band | instrument | song writer | original member |\n",
    "|:-----|:--|:-:|:-:|:-:|:-:|\n",
    "|0 | 'John Lennon' | 'Beatles' | 'Guitar' | 'yes' | 'yes' |\n",
    "|1 | 'Morris Day'| 'The Time'| 'Vocals'| 'no' | 'yes' |\n",
    "|2 | 'Robert Trujillo'| 'metalica' | 'Bass'| 'no' | 'no' |\n",
    "|3 | 'Prince'| 'The Time| 'Multi'| 'yes' | 'yes' |\n",
    "|4 | 'Pete Best' | 'Beatles' | 'Drums' | 'no' | 'yes' |\n",
    "\n",
    "This is a simple example of a `DataFrame` and theres loads of ways to make them, but more often than not, as a social science researcher you'll be importing your data into a `DataFrame` rather than creating them from scratch. In the cell below we're going to demonstrate how you might make a `DataFrame` from some `lists`, but you can also make them from `dicts`, and other types of objects as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise some list objects that contains our data, this could also be a list of lists, or a dict of lists for example\n",
    "\n",
    "names = ['John Lennon', 'Morris Day', 'Robert Rtujillo', 'Prince', 'Pete Best', 'Frank Zappa']\n",
    "bands = ['Beatles', 'The Time', 'metalica', 'The Time', 'Beatles', 'The Mothers']\n",
    "instruments = ['Guitar', 'Vocals', 'Bass', 'Multi', 'Drums', 'Multi']\n",
    "writer = ['yes', 'no', 'no', 'yes', 'no', 'yes']\n",
    "orig = ['yes', 'yes', 'no', 'yes', 'yes', 'yes']\n",
    "\n",
    "bands_df = pd.DataFrame(# opening brackets but moving to new line for readability, note the uppercase D and F in the call\n",
    "    list(zip(names,bands, instruments, writer, orig )), #first argument note the comma at the end of it, this is a couple of nested functions\n",
    "    columns = ['Participant name', 'band', 'instrument', 'song writer', 'original member']# second argument , passing a list to the columns arguments\n",
    "    )# closing the first pair of brackets to complete the function call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats just an example of how you can make a `DataFrame` by hand if you need to, which can be really useful if you need to make an example data set to get a question answered online without sharing participant data with d'internet. \n",
    "\n",
    "All we did was use the `DataFrame` `constructor` to some `list` objects and turn them into a `DataFrame` object. \n",
    "\n",
    "#### a note on `constructors`\n",
    "Now that we've shown you a couple of examples of `constructors` it will hopefully be clear that a `constructor` is just a speacial type of `function` that creates an `object` of a certain `class`. A `class` is just pythons name for a datatype, so other examples of classes are `lists`, `ints`, `dicts`, `Paths`, and of course `DataFrames`. Some of you noticed this when you called the `type()` `function` on objects in earlier workshops. It tells us the `class` of a given object. Run the cell below for a reminder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(names))\n",
    "print(type(names[0]))\n",
    "print(type(example_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you might note from `pl.Path()` and `pd.DataFrame()` is that both of these `constructor functions` use uppercase letters. Most `constructors` do, with the exception of the python basic classes like `list()`, `int()`, `dict()` etc, we don't know why these constructors are different but since they aren't used that often it doesn't really matter. Generally speaking a `constructor` will use uppercase letters at the start of each word in the name. This is why we've discouraged you from using uppercase letters in your own functions, if another python user saw uppercase letters in your `functions` they'd think it was a `constructor`. \n",
    "\n",
    "\n",
    "### Importing your data into a pandas `DataFrame`\n",
    "As we said above, it's useful to know how to make a `DataFrame` by hand. However, you will be `reading` data into a `Dataframe` much more often, for example importing data from SPSS files sent by someone else, or reading in a `.csv` or a `.xlsx` file from qualtrics, and pandas has a number of `pd.read...()` `functions` to allow you to do this easily. In the cell below we're showing you an example of the `read_csv() function` which, unsurprisingly, is what we use to import `.csv` files. We're using the `csvfile` `Path()` variable that you made up in the first `code cell` of this workbook. If it doesn't work below make sure you made the `csvfile` variable properly (and don't forget to run that cell up above).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'df' is the shorthand convention used to name DataFrames, you'll see this all over the internet when looking for answers\n",
    "\n",
    "\n",
    "csv_df = pd.read_csv(csvfile) # using the csvfile Path variable inside read_csv() to import data to DataFrame "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boom you've just imported your first dataset into pandas. You'll practice it yourself with the SPSS version of the file. \n",
    "\n",
    "If you want to (and we really encourage you) to read up on `read_csv()` you should check out the [pandas documentation at this link](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html). You'll see that `read_csv()` can take loads of `arguments` which allows you to specify how you want the data to be imported. Which is really handy because not everyone makes nice data. As always you don't need to memorise all of those arguments now, just know they're there and you can always look for examples online if you come up against something tricky, but for right now just note the `syntax`\n",
    "\n",
    "```\n",
    "df_name = pd.read_csv('path/to/my/file.csv')\n",
    "```\n",
    "\n",
    "### The anatomy of a `DataFrame`\n",
    "One of things thats great about `DataFrames` is that they have a very simple structure which allows us to work with them really easily. Too start out with we're going to look at the `head()`, the `tail()`, the `columns` and the `index`. \n",
    "\n",
    "####  `df.head()`\n",
    "The `head` of a `DataFrame` is just the first *n* rows of a `DataFrame`, which is great because often your data set will be really big (loads of participants with loads of observations) and so you only need to check a few rows. In the cell below we've called the `head()` of the bands `DataFrame` from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant name</th>\n",
       "      <th>band</th>\n",
       "      <th>instrument</th>\n",
       "      <th>song writer</th>\n",
       "      <th>original member</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Lennon</td>\n",
       "      <td>Beatles</td>\n",
       "      <td>Guitar</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morris Day</td>\n",
       "      <td>The Time</td>\n",
       "      <td>Vocals</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert Rtujillo</td>\n",
       "      <td>metalica</td>\n",
       "      <td>Bass</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prince</td>\n",
       "      <td>The Time</td>\n",
       "      <td>Multi</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pete Best</td>\n",
       "      <td>Beatles</td>\n",
       "      <td>Drums</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant name      band instrument song writer original member\n",
       "0      John Lennon   Beatles     Guitar         yes             yes\n",
       "1       Morris Day  The Time     Vocals          no             yes\n",
       "2  Robert Rtujillo  metalica       Bass          no              no\n",
       "3           Prince  The Time      Multi         yes             yes\n",
       "4        Pete Best   Beatles      Drums          no             yes"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bands_df.head() # calling the first 5 rows of the bands data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *keen-eyed* amongst you might notice that `.head()` prints out the first **5** rows of the dataset, so poor Frank Zappa doesn't get included. **5** is the default value for `.head()`, but we can change that by just putting an `int` between the brackets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant name</th>\n",
       "      <th>band</th>\n",
       "      <th>instrument</th>\n",
       "      <th>song writer</th>\n",
       "      <th>original member</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Lennon</td>\n",
       "      <td>Beatles</td>\n",
       "      <td>Guitar</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morris Day</td>\n",
       "      <td>The Time</td>\n",
       "      <td>Vocals</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert Rtujillo</td>\n",
       "      <td>metalica</td>\n",
       "      <td>Bass</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant name      band instrument song writer original member\n",
       "0      John Lennon   Beatles     Guitar         yes             yes\n",
       "1       Morris Day  The Time     Vocals          no             yes\n",
       "2  Robert Rtujillo  metalica       Bass          no              no"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bands_df.head(3) # displaying the first 3 rows of the bands data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So `.head()` isn't really limited to a set amount of rows (*n*) but 5 is generally more than enough, if you want more just ask for more with a larger `int` in the brackets. \n",
    "\n",
    "#### `df.tail()`\n",
    "We're pretty sure you can guess what `.tail()` does... it displays the last *n* rows of a `DataFrame`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant name</th>\n",
       "      <th>band</th>\n",
       "      <th>instrument</th>\n",
       "      <th>song writer</th>\n",
       "      <th>original member</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morris Day</td>\n",
       "      <td>The Time</td>\n",
       "      <td>Vocals</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert Rtujillo</td>\n",
       "      <td>metalica</td>\n",
       "      <td>Bass</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prince</td>\n",
       "      <td>The Time</td>\n",
       "      <td>Multi</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pete Best</td>\n",
       "      <td>Beatles</td>\n",
       "      <td>Drums</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Frank Zappa</td>\n",
       "      <td>The Mothers</td>\n",
       "      <td>Multi</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant name         band instrument song writer original member\n",
       "1       Morris Day     The Time     Vocals          no             yes\n",
       "2  Robert Rtujillo     metalica       Bass          no              no\n",
       "3           Prince     The Time      Multi         yes             yes\n",
       "4        Pete Best      Beatles      Drums          no             yes\n",
       "5      Frank Zappa  The Mothers      Multi         yes             yes"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bands_df.tail()# calling there last 5 rows of the bands data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's Frank!\n",
    "\n",
    "You can also specify the number of rows with an int between the brackets. \n",
    "\n",
    "\n",
    "#### class methods\n",
    "You'll note that the `syntax` above is a little different, instead of `head()` being called like a `function` (e.g. `head(bands_df)`) we instead use the `syntax`:\n",
    "\n",
    "```\n",
    "df.head()\n",
    "```\n",
    "\n",
    "This is beacuse `head()` and `tails()` are `calss methods`. Methods are, basically, a type of function that can *only run* on objects of a `*certain class*`. There's more to it than this but thats all you need to know to use them. If you want to `define` you're own `classes` and thus make your own `class methods` then you should take some time to go through [this set of youtube tutorials](https://www.youtube.com/watch?v=Z1Yd7upQsXY&list=PLP_zqJ75jdgoqr3oiDA21o_K8p8GFRWHa) is really good. \n",
    "\n",
    "*Honestly, its well worth your time anyway.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pyreadstat'.  Use pip or conda to install pyreadstat.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KEVIN~1.OMA\\AppData\\Local\\Temp/ipykernel_22516/1691195063.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mSPSSfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\kevin.omalley\\OneDrive - University of Limerick\\Documents\\GitHub\\ULpsych_programing_club\\data\\raw_data_spss.sav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_spss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_spss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSPSSfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\kevin.omalley\\Desktop\\venvs\\research\\lib\\site-packages\\pandas\\io\\spss.py\u001b[0m in \u001b[0;36mread_spss\u001b[1;34m(path, usecols, convert_categoricals)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \"\"\"\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mpyreadstat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pyreadstat\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0musecols\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin.omalley\\Desktop\\venvs\\research\\lib\\site-packages\\pandas\\compat\\_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'pyreadstat'.  Use pip or conda to install pyreadstat."
     ]
    }
   ],
   "source": [
    "#This cell won't work yet, run it to see the error. \n",
    "\n",
    "SPSSfile = pl.Path(r'C:\\Users\\kevin.omalley\\OneDrive - University of Limerick\\Documents\\GitHub\\ULpsych_programing_club\\data\\raw_data_spss.sav')\n",
    "\n",
    "df_spss = pd.read_spss(SPSSfile)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da3e0b0f4dc5d44db4d7e0a7396f401911ef6d0325c18f6517bd5ad3af6d2cfb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('research': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
