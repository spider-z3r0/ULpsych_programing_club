{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7 - Saving data (Like a bawce!)\n",
    "\n",
    "Welcome back to these python for SPSS users workshops. Over the last couple of weeks we have introduced you to some of the basics of working with data in python using the `pandas` module. We've introduced you to `dataframes` and some of the ways you can create them, such as creating them from scratch (`pd.DataFrame()`) or 'reading' in your data from .csv files (`pd.read_csv()`) or .sav files (`pd.read_spss()`). \n",
    "\n",
    "We then went on to talking about examining your `df` by checking things like the `head()`, `tail()`, `shape`, and `columns`. Then we took this further by looking at `slicing` our data to get specific rows and columns based on their numerical index. \n",
    "\n",
    "This week and next week we're going to 'finish' up the python part of these workshops by generating some descriptive statistics, simple plots, and saving output. But first things first - we need some data. \n",
    "\n",
    "Remember that the first thing we do is import the modules we'll need, so in the cell below please import `pandas`, `pathlib`, and `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the needed modules in this cell\n",
    "import pandas as pd\n",
    "import pathlib as pl\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! Modules imported and now we need some data. Read through and run the cell below to create the `movies_df` so that we have some data to work with. \n",
    "\n",
    "(Do actually read through the cell and try to make sense of what we've done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant Name</th>\n",
       "      <th>Movie Title</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Year of Release</th>\n",
       "      <th>ImdB Score</th>\n",
       "      <th>Rotten Tomatoes Score</th>\n",
       "      <th>Gender of Lead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Carpenter</td>\n",
       "      <td>The Thing</td>\n",
       "      <td>Horror</td>\n",
       "      <td>1982</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nicolas Winding Refn</td>\n",
       "      <td>Drive</td>\n",
       "      <td>Action</td>\n",
       "      <td>2011</td>\n",
       "      <td>78.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Matthijs van Heijningen</td>\n",
       "      <td>The Thing</td>\n",
       "      <td>Horror</td>\n",
       "      <td>2011</td>\n",
       "      <td>62.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dennis Villanueve</td>\n",
       "      <td>Arrival</td>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>2016</td>\n",
       "      <td>79.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coen Brothers</td>\n",
       "      <td>No Country for Old Men</td>\n",
       "      <td>Drama</td>\n",
       "      <td>2007</td>\n",
       "      <td>82.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Participant Name             Movie Title   Genre Year of Release  \\\n",
       "0           John Carpenter               The Thing  Horror            1982   \n",
       "1     Nicolas Winding Refn                   Drive  Action            2011   \n",
       "2  Matthijs van Heijningen               The Thing  Horror            2011   \n",
       "3        Dennis Villanueve                 Arrival  Sci-Fi            2016   \n",
       "4            Coen Brothers  No Country for Old Men   Drama            2007   \n",
       "\n",
       "   ImdB Score  Rotten Tomatoes Score Gender of Lead  \n",
       "0        82.0                   82.0           Male  \n",
       "1        78.0                   93.0           Male  \n",
       "2        62.0                   34.0         Female  \n",
       "3        79.0                   94.0           Male  \n",
       "4        82.0                   93.0         Female  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialise some list objects that contains our data, this could also be a list of lists, or a dict of lists for example\n",
    "director = ['John Carpenter', '', 'Nicolas Winding Refn', 'Matthijs van Heijningen', 'Damien Chazelle', 'Dennis Villanueve', 'Coen Brothers', 'Kelly Asbury', 'Edgar Wright', 'Coen Brothers']\n",
    "names = ['The Thing', 'Blade Runner 2049', 'Drive',  'The Thing', 'Whiplash', 'Arrival', 'No Country for Old Men', 'Shrek 2', 'Hot Fuzz', 'Fargo']\n",
    "genre = ['Horror', 'Sci-Fi', 'Action', 'Horror', 'Drama', 'Sci-Fi', 'Drama', 'Comedy', 'Comedy', 'Dark Comedy']\n",
    "year = ['1982', '2017', '2011', '2011', '2014', '2016', '2007', '2004', '2007', '1996']\n",
    "imdb_score = [82, 80, 78, 62, np.nan, 79, 82, 73, 78, 81]\n",
    "rt_critics = [82, 88, 93, 34, np.nan, 94, 93, 89, 91, 94]\n",
    "lead = ['male', 'Male', 'm', 'Female', 'm', 'Male', 'fem', 'Orgre', 'Male', 'Male']\n",
    "\n",
    "\n",
    "#turning those lists into a dataframe\n",
    "movies_df = pd.DataFrame(# opening brackets but moving to new line for readability, note the uppercase D and F in the call\n",
    "    list(zip(director, names, genre, year, imdb_score, rt_critics, lead)), #first argument note the comma at the end of it, this is a couple of nested functions\n",
    "    columns = ['Participant Name', 'Movie Title', 'Genre', 'Year of Release', 'ImdB Score', 'Rotten Tomatoes Score', 'Gender of Lead']# second argument , passing a list to the columns arguments\n",
    "    )# closing the first pair of brackets to complete the function call\n",
    "\n",
    "\n",
    "# cleaning the data a little. \n",
    "movies_df = movies_df.replace(r'^\\s*$', np.nan, regex=True).dropna().reset_index(drop=True) #\n",
    "#notice how we've 'chained' a bunch of methods together to make all empty cells appear as 'np.nan', then dropping all 'nan' cells then resetting the index\n",
    "#that one line of code! Imagine if it was a huge data set\n",
    "\n",
    "movies_df.iloc[:, -1:] = movies_df.iloc[:, -1:].replace(to_replace = [\"m\"], value = \"Male\") #Fixing the male values\n",
    "movies_df.iloc[:, -1:] = movies_df.iloc[:, -1:].replace(to_replace = [\"fem\"], value = \"Female\") # fixing the female values\n",
    "movies_df['Gender of Lead'] = movies_df['Gender of Lead'].str.capitalize()\n",
    "\n",
    "movies_df.head()# displaying the first 5 columns of the movies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now that we have some data to work with we can start to play around a little. \n",
    "\n",
    "\n",
    "## Saving data\n",
    "\n",
    "One of the key things we might want to do is **save** our data now that we've made it. In this case we've made the dataset somewhat from scratch and maybe we want to be able to save it so that we can send it onto other researchers, or maybe you have done lots of work cleaning a data set and you want to save it so that yo ucan comeback and analyse it in a new jupyter notebook later. \n",
    "\n",
    "Saving your data is a good idea and fortunately the syntax for saving a dataframe is, at the heart of it, really easy. \n",
    "\n",
    "\n",
    "```\n",
    "#saving a dataframe to a csv file\n",
    "name_of_dataframe.to_csv('path\\to\\where\\you\\want\\to\\save\\filename.csv')\n",
    "\n",
    "#saving a dataframe to an excel file\n",
    "name_of_dataframe.to_excel('path\\to\\where\\you\\want\\to\\save\\filename.xlsx')\n",
    "\n",
    "``` \n",
    "\n",
    "So above, we have two examples of saving a `pandas DataFrame`, one to a `.csv` file and one to a `.xlsx` file. Let's just take a second and walk through the actual syntax we used above. \n",
    "\n",
    "\n",
    " 1. The first thing we do is call the `variable` we want to work on, in this case using the name of our dataframe\n",
    " 2. We follow this with a fullstop `.` because saving a file is method (go back and check out week 6 for a little bit about class methods)\n",
    " 3. This is followed by `to_` and then the type of file we're exporting to, so `to_csv` for csvs or `to_excel` \n",
    " 4. Then we open brackets `()` and we pass the `path` to where we want the file to live \n",
    "    1. This can be an `r-string` \n",
    "    2. Or it can be a `pl.Path()` object\n",
    "    3. but it has to end in `\\filename.filetype`\n",
    "\n",
    "\n",
    "Whether or not you use an `r-string` or a `Path` is often a matter of personal prefernce, but we would encourage you to work with `Path` objects more often because they can be a lot more flexible. Let's take an aside for a few minutes and look at what we can do with `Paths` to make our lives easier. \n",
    "\n",
    "## Path components \n",
    "\n",
    "Much like a `DataFrame` has attributes like `.columns` and `.shape`, a `Path` object also has attributes that can be useful, and these attributes are bassically just the components of a file path. For a really good breakdown of the `pathlib` module you should check out [this tutorial](https://realpython.com/python-pathlib/) (in particular take a look at the 'Picking out the components of a path' section). These `attributes` allow us to pick apart a `path` so that we can use the bits of it we need. To get a sense of this, in the cell below create a `Path` to the `csv` version of the raw data we sent you in week 5 (it should be called 'raw_data_csv.csv' and it should be in the 'data' sub-folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make your path object on the next line\n",
    "\n",
    "csv_file = pl.Path(r'C:\\Users\\kevin.omalley\\OneDrive - University of Limerick\\Documents\\GitHub\\ULpsych_programing_club\\data\\raw_data_csv.csv')#just paste the path to your file between the ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an example path, we can can look at some of the attributes.\n",
    "\n",
    "### name\n",
    "if we want to get the name of the file or folder that a `path` points to, we just use the syntax\n",
    "\n",
    "```\n",
    "file_variable.name\n",
    "```\n",
    "\n",
    "In the cell below, try printing out the name of the csv_file variable you made up above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'raw_data_csv.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the name of your csv file in this cell\n",
    "csv_file.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boom. \n",
    "\n",
    "You'll notice that the filename also has the `.csv` extenstion after the name. Obviously if it was an excel workbook the extension would be `.xlsx` and if it was a jupyter notebook it would be `.ipynb`. In the context of `Path` objects, these are called the `suffix` of a file (folders don't have `suffixes`) and you can call them with the syntax \n",
    "\n",
    "```\n",
    "file_variable.suffix\n",
    "```\n",
    "\n",
    "In the cell below, print out the `suffix` of your file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the name of your csv file in this cell\n",
    "csv_file.suffix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these `attributes` return `strings` that you can perform all the usual `string operations` on, and we know how much you love those (honestly, it's endearing). But we can also also access the `path` to the folder your file (or subfolder) is in by calling the `parent`.\n",
    "```\n",
    "file_or_folder.parent\n",
    "```\n",
    "\n",
    "In the cell below, print out the `parent` of the the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/kevin.omalley/OneDrive - University of Limerick/Documents/GitHub/ULpsych_programing_club/data')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the parent of the csv file\n",
    "csv_file.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than being a `string` object, this `parent` object is also a `Path` and what is useful about this is we can use some of `pathlibs` built in functionality to make our lives a little easier.\n",
    "\n",
    "For example, we can add to an existing path by using `syantax` that is very similar to `string concatenation` oniy instead of using `+` to join to strings together, we can use `/` (forwardslash) to join a `string` onto the end of the `parent Path` for when we want to save a new file in the same folder as an existing file **without overwriting our old file**. \n",
    "\n",
    "```\n",
    "new_file_path = old_file_path.parent / 'new_filename.filetype'\n",
    "```\n",
    "\n",
    "So what we've done there is taken the `parent folder` of our original `Path` and added a new `.name` (which includes with `suffix`). We've also saved this as a `variable` so we can call it if we need it. \n",
    "\n",
    "We can combine this `syntax` with the `syntax` we use to save dataframes\n",
    "\n",
    "```\n",
    "#to save a csv file\n",
    "dataframe.to_csv(old_file_path.parent/'new_file.csv') # pay close attention to the syntax\n",
    "```\n",
    "\n",
    "In the cell below, try saving `movies_df` to the `parent` of the `csv_file` `Path`. Take you're time with it and really think through the syntax example above. \n",
    "\n",
    "You should see the file show up in the 'data' sub-folder of our programming club directory. \n",
    "\n",
    "You can open it using excel, and you can also view it in vscode. Take a look at it.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the movies df into a csv file\n",
    "# call the file 'movies.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you open up the movies.csv file you might notice that there is an extra column at the start of the dataframe. Like so\n",
    "\n",
    "|    |   Unnamed: 0 | Participant Name        | Movie Title            | Genre       |   Year of Release |   ImdB Score |   Rotten Tomatoes Score | Gender of Lead   |\n",
    "|---:|-------------:|:------------------------|:-----------------------|:------------|------------------:|-------------:|------------------------:|:-----------------|\n",
    "|  0 |            0 | John Carpenter          | The Thing              | Horror      |              1982 |           82 |                      82 | Male             |\n",
    "|  1 |            1 | Nicolas Winding Refn    | Drive                  | Action      |              2011 |           78 |                      93 | Male             |\n",
    "|  2 |            2 | Matthijs van Heijningen | The Thing              | Horror      |              2011 |           62 |                      34 | Female           |\n",
    "|  3 |            3 | Dennis Villanueve       | Arrival                | Sci-Fi      |              2016 |           79 |                      94 | Male             |\n",
    "|  4 |            4 | Coen Brothers           | No Country for Old Men | Drama       |              2007 |           82 |                      93 | Female           |\n",
    "|  5 |            5 | Kelly Asbury            | Shrek 2                | Comedy      |              2004 |           73 |                      89 | Orgre            |\n",
    "|  6 |            6 | Edgar Wright            | Hot Fuzz               | Comedy      |              2007 |           78 |                      91 | Male             |\n",
    "|  7 |            7 | Coen Brothers           | Fargo                  | Dark Comedy |              1996 |           81 |                      94 | Male             |\n",
    "\n",
    " This is the `index` of the dataframe. Often however, we do not want to save the `index` when we save a dataset (sometimes we really do) and so we need to use a `keyword argument` in the `df.to_csv()` method \n",
    "\n",
    "```\n",
    "df.to_csv(path, index = False)#index is a keyword argument, setting it to false means that the index will not show up as a column in the exported csv\n",
    "```\n",
    "\n",
    "In the cell below save the `movies_df` again, but this time call it `movies_2.csv` and set `index =False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the movies df without the index column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unless you have decided to use a different column as the index (like maybe the participant_id) or you have a `multiindex` dataframe (look it up, they are cool) you will rarely want to include the     `index` as a column in an exported dataframe, so setting `index = False` is a reasonable habbit to get into. Other wise, you will always have to `drop` the first column, or do some kind of `iloc` selection when you import your cleaned dataframe for analysis. \n",
    "\n",
    "\n",
    "Now, here comes the big practice bit. \n",
    "\n",
    "For the rest of this session, we want you to import the SPSS version of the raw data (raw_data_spss.sav) into a pandas dataframe, clean it up (select only the needed columns, clean up any missing or inconsistent data) and then save it to a new csv file, so we can do some simple analysis and charting next week. Remember the the `pathlib` tricks we just talked about up above when importing and saving the data. We're going to talk you through some of the specifics that come up when working with SPSS data (you probably don't need to ask us how we feel about SPSS files...)\n",
    "\n",
    "## Importing SPSS files. \n",
    "\n",
    "Earlier in these series of courses we, introduced you to importing datafiles into `pandas DataFrames` and we did this mainly with `.csv` files, but we tricked you into installing the `pyreadstat` module as well, because this is needed to allow python to read `.sav` files. Once you have `pyreadstat` installed in your `venv` you can just use the simple `pd.read_spss(path)` to improt your dataframe. \n",
    "\n",
    "We can do this three ways:\n",
    "\n",
    " 1. We can create a whole new Path object to our spss file\n",
    " 2. We can use the `parent` of the `csv_file` Path with `/ 'raw_data_spss.sav'` \n",
    " 3. We can just copy the path for the spss file and paste it as an `r_string` into the `read_spss()` method.\n",
    "\n",
    "Because we have already made a `path` object, it might be most efficient to just use the parent of that object, but any of those methods will work. \n",
    "\n",
    "Import the `.sav` version of the raw data into a dataframe called `sdf1` below, using whichever method you prefer. Or try it a few times, changing the approach each time, im not your damn boss!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the .sav file into a pandas dataframe in the cell below\n",
    "\n",
    "sdf1 = pd.read_spss()# importing the spss data to a pandas df\n",
    "sdf1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Status</th>\n",
       "      <th>IPAddress</th>\n",
       "      <th>Progress</th>\n",
       "      <th>Duration__in_seconds_</th>\n",
       "      <th>Finished</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>RecipientLastName</th>\n",
       "      <th>...</th>\n",
       "      <th>Q_5</th>\n",
       "      <th>Q_6</th>\n",
       "      <th>Q_7</th>\n",
       "      <th>Q_8</th>\n",
       "      <th>Q_9</th>\n",
       "      <th>Q_10</th>\n",
       "      <th>Q_11</th>\n",
       "      <th>FL_12_DO_positive</th>\n",
       "      <th>FL_12_DO_negative</th>\n",
       "      <th>FL_12_DO_control</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-02 11:17:34</td>\n",
       "      <td>2022-02-02 11:17:34</td>\n",
       "      <td>Survey Preview</td>\n",
       "      <td>193.1.100.60</td>\n",
       "      <td>100.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-02-02 11:17:34</td>\n",
       "      <td>R_FK38</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Agree strongly</td>\n",
       "      <td>Agree strongly</td>\n",
       "      <td>Agree strongly</td>\n",
       "      <td>Agree strongly</td>\n",
       "      <td>Agree strongly</td>\n",
       "      <td>Agree strongly</td>\n",
       "      <td>Agree strongly</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-02 11:21:32</td>\n",
       "      <td>2022-02-02 11:21:32</td>\n",
       "      <td>Survey Preview</td>\n",
       "      <td>193.1.100.60</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-02-02 11:21:32</td>\n",
       "      <td>R_MV94</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-02-02 11:21:42</td>\n",
       "      <td>2022-02-02 11:21:42</td>\n",
       "      <td>Survey Preview</td>\n",
       "      <td>193.1.100.60</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-02-02 11:21:42</td>\n",
       "      <td>R_OT20</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Agree strongly</td>\n",
       "      <td>Disagree a little</td>\n",
       "      <td>Neither agree or disagree</td>\n",
       "      <td>Disagree moderately</td>\n",
       "      <td>Disagree a little</td>\n",
       "      <td>Disagree a little</td>\n",
       "      <td>Disagree a little</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-02-09 08:07:06</td>\n",
       "      <td>2022-02-09 08:07:06</td>\n",
       "      <td>Survey Preview</td>\n",
       "      <td>193.1.100.60</td>\n",
       "      <td>100.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-02-09 08:07:06</td>\n",
       "      <td>R_VA79</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Disagree moderately</td>\n",
       "      <td>Neither agree or disagree</td>\n",
       "      <td>Agree moderately</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agree strongly</td>\n",
       "      <td>Agree a little</td>\n",
       "      <td>Disagree moderately</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-09 08:07:34</td>\n",
       "      <td>2022-02-09 08:07:34</td>\n",
       "      <td>Survey Preview</td>\n",
       "      <td>193.1.100.60</td>\n",
       "      <td>100.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-02-09 08:07:34</td>\n",
       "      <td>R_PW73</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neither agree or disagree</td>\n",
       "      <td>Disagree strongly</td>\n",
       "      <td>Agree a little</td>\n",
       "      <td>Neither agree or disagree</td>\n",
       "      <td>Disagree moderately</td>\n",
       "      <td>Agree a little</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            StartDate             EndDate          Status     IPAddress  \\\n",
       "0 2022-02-02 11:17:34 2022-02-02 11:17:34  Survey Preview  193.1.100.60   \n",
       "1 2022-02-02 11:21:32 2022-02-02 11:21:32  Survey Preview  193.1.100.60   \n",
       "2 2022-02-02 11:21:42 2022-02-02 11:21:42  Survey Preview  193.1.100.60   \n",
       "3 2022-02-09 08:07:06 2022-02-09 08:07:06  Survey Preview  193.1.100.60   \n",
       "4 2022-02-09 08:07:34 2022-02-09 08:07:34  Survey Preview  193.1.100.60   \n",
       "\n",
       "   Progress  Duration__in_seconds_ Finished        RecordedDate ResponseId  \\\n",
       "0     100.0                  126.0     True 2022-02-02 11:17:34     R_FK38   \n",
       "1     100.0                   20.0     True 2022-02-02 11:21:32     R_MV94   \n",
       "2     100.0                   10.0     True 2022-02-02 11:21:42     R_OT20   \n",
       "3     100.0                  230.0     True 2022-02-09 08:07:06     R_VA79   \n",
       "4     100.0                   40.0     True 2022-02-09 08:07:34     R_PW73   \n",
       "\n",
       "  RecipientLastName  ...                  Q_5                        Q_6  \\\n",
       "0                    ...       Agree strongly             Agree strongly   \n",
       "1                    ...                  NaN                        NaN   \n",
       "2                    ...       Agree strongly          Disagree a little   \n",
       "3                    ...  Disagree moderately  Neither agree or disagree   \n",
       "4                    ...                  NaN  Neither agree or disagree   \n",
       "\n",
       "                         Q_7                  Q_8                        Q_9  \\\n",
       "0             Agree strongly       Agree strongly             Agree strongly   \n",
       "1                        NaN                  NaN                        NaN   \n",
       "2  Neither agree or disagree  Disagree moderately          Disagree a little   \n",
       "3           Agree moderately                  NaN             Agree strongly   \n",
       "4          Disagree strongly       Agree a little  Neither agree or disagree   \n",
       "\n",
       "                  Q_10                 Q_11 FL_12_DO_positive  \\\n",
       "0       Agree strongly       Agree strongly               1.0   \n",
       "1                  NaN                  NaN               NaN   \n",
       "2    Disagree a little    Disagree a little               NaN   \n",
       "3       Agree a little  Disagree moderately               1.0   \n",
       "4  Disagree moderately       Agree a little               NaN   \n",
       "\n",
       "   FL_12_DO_negative FL_12_DO_control  \n",
       "0                NaN              NaN  \n",
       "1                NaN              NaN  \n",
       "2                NaN              1.0  \n",
       "3                NaN              NaN  \n",
       "4                1.0              NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf1 = pd.read_spss(csv_file.parent / 'raw_data_spss.sav')# importing the spss data to a pandas df\n",
    "sdf1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a quick look at the `head` of `sdf1`. \n",
    "\n",
    "Firstly, we can see that, as with all Qualtrics datasets, it contains a lot of extra columns, and because this Qualtrics survey was programmed by a lunatic, obviously living fast with no regard for others, some of the columns are named things like 'Q_5... truly this was made by a monster... \n",
    "\n",
    "You can also see that the we have some columns ('Q_1' to 'Q_11') that appear to be likert style scale items, and they appear to have the value labels instead of the values. This might make it difficult to calculate a total score (beacuse we have words where we would need numbers). Let's tackle these issues one at a time starting with removing the unwanted columns from our dataset. \n",
    "\n",
    "## Getting rid of unwanted columns. \n",
    "\n",
    "Depending on what you want to do there are a few ways get rid of columns that you don't want in your dataset, we can \n",
    " 1. drop the unwanted columns us `df.drop()` \n",
    " 2. select the wanted columns using `.iloc` or `.loc`\n",
    "and which you choose just depends on your needs, your dataset, and your preference. Lets start by looking at `df.drop()`\n",
    "\n",
    "### Dropping columns\n",
    "\n",
    "At this stage it might be pretty clear to you what `.drop()` does, partly because you've already seen the `.dropna()` method. Both of these methods allow us to just delete rows or columns from our `df`. With `dropna()` just we can quickly and easily delete alls rows that contain empty cells, `drop()` however, allows us to have a lot more control over what we're doing. In it's simplest form we use the `syntax`\n",
    "\n",
    "```\n",
    "new_df = df.drop('Column name', axis = 1)# dropping a single column\n",
    "newer_df = df.drop(['col1', 'col2' ...], axis = 1)# dropping a list of columns\n",
    "```\n",
    "\n",
    "This `syntax` should be pretty familiar to you, we're using the `.drop()` method on our `df` to `return` a new `df` that doesn't have the columns we dropped in it. *Simples!*\n",
    "\n",
    "If you want to make the changes to your original `df` object you just use its name at the start of the `syntax`\n",
    "\n",
    "```\n",
    "df = df.drop('Column name', axis = 1)# dropping a single column *within* the same dataframe\n",
    "```\n",
    "\n",
    "This will overwrite your `padas DataFrame` but it won't make changes to the file you imported it from. There will be times when you want to overwrite, and there will be time when you want to make a new `df`, you'll develop a sense of which is better. As long as you're not overwiting you **Raw Data file**, the one you've imported you data from originally, it really just depends on what you prefer.\n",
    "\n",
    "However, knowing the exact name of each column matters. If you get the column name wrong you'll get an error and so what we might want to do is have a full list of all the columns (and the index number of those columns) `for`tunately we've already shown you a way to `loop` through this. Go back to the week 3 and week 4 and try to figure out how to print out the index and item `for each item in the sdf1.columns list`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do your printing magic here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 = StartDate\n",
      "1 = EndDate\n",
      "2 = Status\n",
      "3 = IPAddress\n",
      "4 = Progress\n",
      "5 = Duration__in_seconds_\n",
      "6 = Finished\n",
      "7 = RecordedDate\n",
      "8 = ResponseId\n",
      "9 = RecipientLastName\n",
      "10 = RecipientFirstName\n",
      "11 = RecipientEmail\n",
      "12 = ExternalReference\n",
      "13 = LocationLatitude\n",
      "14 = LocationLongitude\n",
      "15 = DistributionChannel\n",
      "16 = UserLanguage\n",
      "17 = consent\n",
      "18 = age\n",
      "19 = Q_1\n",
      "20 = Q_2\n",
      "21 = Q_3\n",
      "22 = Q_4\n",
      "23 = Q_5\n",
      "24 = Q_6\n",
      "25 = Q_7\n",
      "26 = Q_8\n",
      "27 = Q_9\n",
      "28 = Q_10\n",
      "29 = Q_11\n",
      "30 = FL_12_DO_positive\n",
      "31 = FL_12_DO_negative\n",
      "32 = FL_12_DO_control\n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate(sdf1.columns):\n",
    "    print(f'{i} = {j}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Boom!*\n",
    "\n",
    "You might notice that the list is too long to be displayed as output in the jupyter notebook, but there is an option to `'Open the full output in a` _text editor_' just under the code cell. If you click that it'll show you the full list. With that list now you can use the `drop()` syntax to get rid of columns that you don't need and have an easier dataset to work on. \n",
    "\n",
    "For example, we could use \n",
    "\n",
    "```\n",
    "sdf2 = sdf1.drop('StartDate', axis = 1)\n",
    "```\n",
    "\n",
    "to save a new version of the dataset that doesn't have the 'StartDate' column. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectnameresearch",
   "language": "python",
   "name": "projectnameresearch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
